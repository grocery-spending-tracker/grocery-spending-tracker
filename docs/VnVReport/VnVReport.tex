\documentclass[12pt, titlepage]{article}

\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=red,
    urlcolor=blue
}
\usepackage[round]{natbib}
\usepackage{longtable}
\usepackage{amsfonts}
\usepackage{float}

\input{../Comments}
\input{../Common}

\begin{document}

\title{Verification and Validation Report: \progname} 
\author{\authname}
\date{\today}
	
\maketitle

\pagenumbering{roman}

\section{Revision History}

\begin{tabularx}{\textwidth}{p{3cm}p{2cm}X}
\toprule {\bf Date} & {\bf Version} & {\bf Notes}\\
\midrule
Date 1 & 1.0 & Notes\\
Date 2 & 1.1 & Notes\\
\bottomrule
\end{tabularx}

~\newpage

\section{Symbols, Abbreviations and Acronyms}

\renewcommand{\arraystretch}{1.2}
\begin{tabular}{l l} 
  \toprule		
  \textbf{symbol} & \textbf{description}\\
  \midrule 
  T & Test\\
  SRS & Software Requirements Specification\\
  MIS & Module Interface Specification\\
  VnV & Verfication and Validation\\
  \bottomrule
\end{tabular}\\

\wss{symbols, abbreviations or acronyms -- you can reference the SRS tables if needed}

\newpage

\tableofcontents

\listoftables %if appropriate

\listoffigures %if appropriate

\newpage

\pagenumbering{arabic}

This document will primarily focus on the test results of the verification and validation process
for the Grocery Spending Tracker application. In particular, the results of the Functional Requirement System Tests,
Nonfunctional Requirement System Tests, and Unit Tests will be covered. Detailed information regarding
the Functional Requirements and Nonfunctional Requirements can be found in the
\href{https://github.com/r-yeh/grocery-spending-tracker/blob/master/docs/SRS/SRS.pdf}{SRS}. Furthermore,
unit tests will focus on the individual modules of the system which can be found in the
\href{https://github.com/r-yeh/grocery-spending-tracker/blob/master/docs/Design/SoftDetailedDes/MIS.pdf}{MIS}.
Finally, detailed information regarding the overall test plan can be found in the
\href{https://github.com/r-yeh/grocery-spending-tracker/blob/master/docs/VnVPlan/VnVPlan.pdf}{VnV Plan}.\\

In addition to test results, this document will also go over feedback from stakeholders and changes due to testing,
the team's approach for automated testing, traceability between tests and requirements/modules, as well as
overall code coverage.

\section{Functional Requirements Evaluation}

This section will cover the test results from the Functional Requirement System Tests
performed for the verification and validation of the Grocery Spending Tracker application.

...

\section{Nonfunctional Requirements Evaluation}

This section goes over the test results from the Nonfunctional Requirement System Tests as
specified in the VnV Plan.

\subsection{Look and Feel}

\begin{longtable}{|l|c|}
  \caption{Look and Feel Testing Summary} \label{Look and Feel Testing Summary} \\
  \toprule
  \textbf{Test ID} & \textbf{Result} \\
  \midrule
  NFRT-LF1 & $\checkmark$ \\
  \midrule
  NFRT-LF2 & $\checkmark$ \\
  \midrule
  NFRT-LF4 & $\checkmark$ \\
  \bottomrule
\end{longtable}

\subsection{Usability}

\begin{longtable}{|l|c|}
  \caption{Usability Testing Summary} \label{Usability Testing Summary} \\
  \toprule
  \textbf{Test ID} & \textbf{Result} \\
  \midrule
  NFRT-UH1 & $\checkmark$ \\
  \midrule
  NFRT-UH2 & $\checkmark$ \\
  \midrule
  NFRT-UH3 & $\checkmark$ \\
  \midrule
  NFRT-UH5 & $\checkmark$ \\
  \midrule
  NFRT-UH6 & $\checkmark$ \\
  \bottomrule
\end{longtable}
		
\subsection{Performance}

\begin{longtable}{|l|c|}
  \caption{Performance Testing Summary} \label{Performance Testing Summary} \\
  \toprule
  \textbf{Test ID} & \textbf{Result} \\
  \midrule
  NFRT-PR1 & $\checkmark$ \\
  \midrule
  NFRT-PR2 & $\checkmark$ \\
  \midrule
  NFRT-PR3 & $\checkmark$ \\
  \midrule
  NFRT-PR4 & $\checkmark$ \\
  \midrule
  NFRT-PR5 & $\checkmark$ \\
  \midrule
  NFRT-PR6 & $\checkmark$ \\
  \bottomrule
\end{longtable}

\subsection{Cultural}

\begin{longtable}{|l|c|}
  \caption{Cultural Testing Summary} \label{Cultural Testing Summary} \\
  \toprule
  \textbf{Test ID} & \textbf{Result} \\
  \midrule
  NFRT-CUR2 & $\checkmark$ \\
  \bottomrule
\end{longtable}

\subsection{Operation and Environment}

\begin{longtable}{|l|c|}
  \caption{Operation and Environment Testing Summary} \label{Operation and Environment Testing Summary} \\
  \toprule
  \textbf{Test ID} & \textbf{Results} \\
  \midrule
  NFRT-OER1 & $\checkmark$ \\
  \midrule
  NFRT-OER2 & $\checkmark$ \\
  \midrule
  NFRT-OER3 & $\checkmark$ \\ 
  \bottomrule
\end{longtable}

\subsection{Security}

\begin{longtable}{|l|c|}
  \caption{Security Testing Summary} \label{Security Testing Summary} \\
  \toprule
  \textbf{Test ID} & \textbf{Results} \\
  \midrule
  NFRT-SR2 & $\checkmark$ \\
  \bottomrule
\end{longtable}
	
% \section{Comparison to Existing Implementation}	

% This section will not be appropriate for every project.

\section{Unit Testing}

This section will go over the test results from the unit tests made as part of the
verification and validation process.

\subsection{Receipt Extraction Module}

The section provides a brief overview of the unit tests performed and their results for the
Receipt Extraction Module.

\begin{longtable}{|l|c|l|c|l|c|}
  \caption{Receipt Extraction Unit Testing Summary} \label{Receipt Extraction Unit Test Summary} \\
  \toprule
  \textbf{Test ID} & \textbf{Result} & \textbf{Test ID} & \textbf{Result} & \textbf{Test ID} & \textbf{Result} \\
  \midrule
  FRT-M3-1 & $\checkmark$ & FRT-M3-2 & $\checkmark$ & FRT-M3-3 & $\checkmark$ \\
  \midrule
  FRT-M3-4 & $\checkmark$ & FRT-M3-5 & $\checkmark$ & FRT-M3-6 & $\checkmark$ \\
  \midrule
  FRT-M3-7 & $\checkmark$ & FRT-M3-8 & $\checkmark$ & FRT-M3-9 & $\checkmark$ \\
  \midrule
  FRT-M3-10 & $\checkmark$ & FRT-M3-11 & $\checkmark$ & FRT-M3-12 & $\checkmark$ \\
  \midrule
  FRT-M3-13 & $\checkmark$ & FRT-M3-14 & $\checkmark$ & FRT-M3-15 & $\checkmark$ \\
  \midrule
  FRT-M3-16 & $\checkmark$ & FRT-M3-17 & $\checkmark$ & FRT-M3-18 & $\checkmark$ \\
  \midrule
  FRT-M3-19 & $\checkmark$ & FRT-M3-20 & $\checkmark$ & FRT-M3-21 & $\checkmark$ \\
  \midrule
  FRT-M3-22 & $\checkmark$ & FRT-M3-23 & $\checkmark$ & FRT-M3-24 & $\checkmark$ \\
  \midrule
  FRT-M3-25 & $\checkmark$ & FRT-M3-26 & $\checkmark$ & ~ & ~ \\
  \bottomrule
\end{longtable}

To summarize, tests FRT-M3-1 to FRT-M3-26 are all frontend tests. These tests focus on the helper functions used
to extract specific information when receiving a chunk of receipt text. FRT-M3-1 to FRT-M3-6 focus on date
extraction with different formats, FRT-M3-7 to FRT-M3-13 test address extraction, FRT-M3-14 to FRT-M3-16 target grocery item extraction,
FRT-M3-17 to FRT-M3-19 focus on subtotal cost extraction, and FRT-M3-20 to FRT-M3-22 tests total cost extraction.
Finally, FRT-M3-23 to FRT-M3-24 and FRT-M3-25 to FRT-M3-26 test updating and JSON conversion for the Item and Grocery Trip
objects respectively. In general, these
tests consist of ideal use cases as well as some edge cases that may appear during use.
For more detailed information regarding the Receipt Extraction Module unit tests, the testing file
can be found here: \href{https://github.com/allanfang1/grocery_spending_tracker_app/blob/main/test/receipt_extraction_test.dart}{receipt extraction
unit tests}.

\subsection{User Analytics Module}

...

\subsection{Users Module}

...

\subsection{Authentication Module}

...

\subsection{Recommendation Engine}

...

\subsection{Classification Engine}

...

\section{Changes Due to Testing}

\wss{This section should highlight how feedback from the users and from 
the supervisor (when one exists) shaped the final product.  In particular 
the feedback from the Rev 0 demo to the supervisor (or to potential users) 
should be highlighted.}

\section{Automated Testing}

On the frontend, all automated tests are carried out using Flutter's built-in testing package.
All tests are located in the "test" folder which is organized by components being tested (found 
\href{https://github.com/allanfang1/grocery_spending_tracker_app/tree/main}{here}). For example,
the \textit{profile\_provider\_test} file executes tests related to the provider for profile functionality.
These tests are executed twice during the development workflow: the first is locally while working on
individual feature branches and the second is on merges/pushes to the "dev" branch of the frontend repository.
The first execution is done manually using \textit{flutter test} in the command line and the second is done
automatically using \textit{Github Actions}.\\

On the backend, automated tests are done using Chai HTTP. Tests are located in the "tests" folder which
is then organized by component and the module being tested 
(found \href{https://github.com/grocery-spending-tracker/grocery-spending-tracker-backend/tree/master/tests}{here}).
As an example, the \textit{userController.analytics.test} file contains unit tests related to the Analytics Module
functionality in the user controller.
These tests are automatically executed during the deployment process of the backend when code is pushed to the
"master" branch of the backend repository. This process is handled by \textit{Github Actions}.
		
\section{Trace to Requirements}
		
\section{Trace to Modules}		

\section{Code Coverage Metrics}

This section goes over the code coverage of the unit tests created for the Grocery Spending Tracker.
For the .dart files, code coverage was calculated using Flutter's built-in testing package. For the .js files,
code coverage was calculated using a Node.js package called c8. A summary of the code coverage achieved for
each tested file can be found in the table below. All files not listed below were considered either out of scope for
unit testing or is being tested as part of the System Tests.

\begin{table}[H]
  \centering
  \caption{Code Coverage Summary} \label{Code Coverage Summary}
  \begin{tabular}{|l|l|}
    \hline
    \textbf{File Name} & \textbf{Line Coverage} \\
    \hline
    extract\_data.dart & 75.9\% \\
    \hline
    capture\_item.dart & 100\% \\
    \hline
    grocery\_trip.dart & 100\% \\
    \hline
    goals\_repository.dart & 86.4\% \\
    \hline
    profile\_repository.dart & 87.9\% \\
    \hline
    history\_repository.dart & 73.7\% \\
    \hline
    db.js & 100\% \\
    \hline
    authController.js & 100\% \\
    \hline
    recommendationController.js & 88.82\% \\
    \hline
    usersController.js & 92.2\% \\
    \hline
    authentication.js & 96.49\% \\
    \hline
    main.js & 81.39\% \\
    \hline
    classifyItem.js & 100\% \\
    \hline
    fuzzyMatching.js & 90.97\% \\
    \hline
    src/classification/util.js & 63.82\% \\
    \hline
    brand.js & 89.47\% \\
    \hline
    fetchProductDetails.js & 94.87\% \\
    \hline
    image.js & 100\% \\
    \hline
    name.js & 89.47\% \\
    \hline
    price.js & 89.47\% \\
    \hline
    productNumber.js & 62.96\% \\
    \hline
    src/scraper/util.js & 100\% \\
    \hline 
  \end{tabular}
\end{table}

\bibliographystyle{plainnat}
\bibliography{../../refs/References}

\newpage{}
\section*{Appendix --- Reflection}

The information in this section will be used to evaluate the team members on the
graduate attribute of Reflection.  Please answer the following question:

\begin{enumerate}
  \item In what ways was the Verification and Validation (VnV) Plan different
  from the activities that were actually conducted for VnV?  If there were
  differences, what changes required the modification in the plan?  Why did
  these changes occur?  Would you be able to anticipate these changes in future
  projects?  If there weren't any differences, how was your team able to clearly
  predict a feasible amount of effort and the right tasks needed to build the
  evidence that demonstrates the required quality?  (It is expected that most
  teams will have had to deviate from their original VnV Plan.)
\end{enumerate}

\end{document}